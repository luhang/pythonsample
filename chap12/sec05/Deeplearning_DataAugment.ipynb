{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# CIFAR-10を読み込んで標準化を含めた前処理を行う\n",
    "import numpy as np\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# CIFAR-10データを読み込む\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "# 画像データをfloat32(浮動小数点数)型に変換\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# 訓練用とテスト用の画像データを標準化する\n",
    "# 4次元テンソルのすべての軸方向に対して平均、標準偏差を求めるので\n",
    "# axis=(0,1,2,3)は省略してもよい\n",
    "mean = np.mean(x_train, axis=(0,1,2,3))\n",
    "std = np.std(x_train, axis=(0,1,2,3))\n",
    "# 標準化する際に標準偏差に極小値を加える\n",
    "x_train = (x_train-mean)/(std+1e-7)\n",
    "x_test = (x_test-mean)/(std+1e-7)\n",
    "\n",
    "# 分類先のクラスの数\n",
    "num_classes = 10\n",
    "# 正解ラベルをワンホット表現に変換\n",
    "y_train = np_utils.to_categorical(y_train,num_classes)\n",
    "y_test = np_utils.to_categorical(y_test,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import regularizers\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "# ハイパーパラメーターの値を設定\n",
    "weight_decay = 1e-4\n",
    "\n",
    "# CNNを構築\n",
    "model = Sequential()\n",
    "\n",
    "# (第1層)畳み込み層1 正則化を行う\n",
    "model.add(\n",
    "    Conv2D(\n",
    "        filters=32,                    # フィルターの数は32\n",
    "        kernel_size=(3,3),             # 3×3のフィルターを使用\n",
    "        input_shape=x_train.shape[1:], # 入力データの形状\n",
    "        padding='same',                # ゼロパディングを行う \n",
    "        kernel_regularizer=regularizers.l2(weight_decay),\n",
    "        activation='relu'              # 活性化関数はReLU\n",
    "        ))\n",
    "# 正規化\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# (第2層)畳み込み層2　正則化を行う\n",
    "model.add(\n",
    "    Conv2D(filters=32,                 # フィルターの数は32\n",
    "           kernel_size=(3,3),          # 3×3のフィルターを使用\n",
    "           padding='same',             # ゼロパディングを行う \n",
    "           kernel_regularizer=regularizers.l2(weight_decay),\n",
    "           activation='relu'           # 活性化関数はReLU\n",
    "           ))\n",
    "# 正規化\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# (第3層)プーリング層1：ウィンドウサイズは2×2\n",
    "model.add(\n",
    "    MaxPooling2D(pool_size=(2,2)))\n",
    "# ドロップアウト1：ドロップアウトは20％\n",
    "model.add(Dropout(0.2))\n",
    " \n",
    "# (第4層)畳み込み層3　正則化を行う\n",
    "model.add(\n",
    "    Conv2D(filters=64,                 # フィルターの数は64\n",
    "           kernel_size=(3,3),          # 3×3のフィルターを使用\n",
    "           padding='same',             # ゼロパディングを行う \n",
    "           kernel_regularizer=regularizers.l2(weight_decay),\n",
    "           activation='relu'           # 活性化関数はReLU\n",
    "           ))\n",
    "\n",
    "# 正規化\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# (第5層)畳み込み層3　正則化を行う\n",
    "model.add(\n",
    "    Conv2D(filters=32,                 # フィルターの数は32\n",
    "           kernel_size=(3,3),          # 3×3のフィルターを使用\n",
    "           padding='same',             # ゼロパディングを行う \n",
    "           kernel_regularizer=regularizers.l2(weight_decay),\n",
    "           activation='relu'           # 活性化関数はReLU\n",
    "           ))\n",
    "# 正規化\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# (第6層)プーリング層2：ウィンドウサイズは2×2\n",
    "model.add(\n",
    "    MaxPooling2D(pool_size=(2,2)))\n",
    "# ドロップアウト2：ドロップアウトは30％\n",
    "model.add(Dropout(0.3))\n",
    " \n",
    "# (第6層)畳み込み層4　正則化を行う\n",
    "model.add(\n",
    "    Conv2D(filters=128,                # フィルターの数は128\n",
    "           kernel_size=(3,3),          # 3×3のフィルターを使用\n",
    "           padding='same',             # ゼロパディングを行う \n",
    "           kernel_regularizer=regularizers.l2(weight_decay),\n",
    "           activation='relu'           # 活性化関数はReLU\n",
    "          ))\n",
    "# 正規化\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# (第7層)畳み込み層5　正則化を行う\n",
    "model.add(\n",
    "    Conv2D(filters=128,                # フィルターの数は128\n",
    "           kernel_size=(3,3),          # 3×3のフィルターを使用\n",
    "           padding='same',             # ゼロパディングを行う \n",
    "           kernel_regularizer=regularizers.l2(weight_decay),\n",
    "           activation='relu'           # 活性化関数はReLU\n",
    "          ))\n",
    "# 正規化\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# (第8層)プーリング層3：ウィンドウサイズは2×2\n",
    "model.add(\n",
    "    MaxPooling2D(pool_size=(2,2)))\n",
    "# ドロップアウト2：ドロップアウトは40％\n",
    "model.add(Dropout(0.4))\n",
    " \n",
    "# Flatten層　4階テンソルから2階テンソルに変換\n",
    "model.add(Flatten())\n",
    "\n",
    "# （第9層）出力層\n",
    "model.add(\n",
    "    Dense(num_classes,           # 出力層のニューロン数はnum_classes\n",
    "          activation='softmax')) # 活性化関数はソフトマックス\n",
    "\n",
    "# Sequentialオブジェクトのコンパイル\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy', # 損失の基準は交差エントロピー誤差\n",
    "    # 最適化アルゴリズムにCNNと相性の良いRMSpropアルゴリズムを使用\n",
    "    optimizer=RMSprop(lr=0.001, decay=1e-6),\n",
    "    metrics=['accuracy'] # 学習評価として正解率を指定\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/130\n",
      "781/781 [==============================] - 691s 885ms/step - loss: 1.9950 - acc: 0.4032 - val_loss: 1.5210 - val_acc: 0.5086\n",
      "Epoch 2/130\n",
      "781/781 [==============================] - 630s 806ms/step - loss: 1.5549 - acc: 0.5315 - val_loss: 1.3740 - val_acc: 0.5600\n",
      "Epoch 3/130\n",
      "781/781 [==============================] - 621s 795ms/step - loss: 1.3895 - acc: 0.5886 - val_loss: 1.1134 - val_acc: 0.6655\n",
      "Epoch 4/130\n",
      "781/781 [==============================] - 628s 805ms/step - loss: 1.3113 - acc: 0.6225 - val_loss: 1.1123 - val_acc: 0.6648\n",
      "Epoch 5/130\n",
      "781/781 [==============================] - 619s 792ms/step - loss: 1.2365 - acc: 0.6460 - val_loss: 1.0438 - val_acc: 0.6972\n",
      "Epoch 6/130\n",
      "781/781 [==============================] - 616s 789ms/step - loss: 1.1793 - acc: 0.6677 - val_loss: 1.0105 - val_acc: 0.7125\n",
      "Epoch 7/130\n",
      "781/781 [==============================] - 619s 792ms/step - loss: 1.1447 - acc: 0.6814 - val_loss: 0.9913 - val_acc: 0.7051\n",
      "Epoch 8/130\n",
      "781/781 [==============================] - 607s 778ms/step - loss: 1.1160 - acc: 0.6923 - val_loss: 0.8691 - val_acc: 0.7530\n",
      "Epoch 9/130\n",
      "781/781 [==============================] - 605s 775ms/step - loss: 1.0712 - acc: 0.7057 - val_loss: 1.0306 - val_acc: 0.7146\n",
      "Epoch 10/130\n",
      "781/781 [==============================] - 620s 793ms/step - loss: 1.0822 - acc: 0.7080 - val_loss: 0.8868 - val_acc: 0.7494\n",
      "Epoch 11/130\n",
      "781/781 [==============================] - 617s 790ms/step - loss: 1.0680 - acc: 0.7156 - val_loss: 0.9478 - val_acc: 0.7539\n",
      "Epoch 12/130\n",
      "781/781 [==============================] - 619s 792ms/step - loss: 1.0283 - acc: 0.7236 - val_loss: 0.9846 - val_acc: 0.7281\n",
      "Epoch 13/130\n",
      "781/781 [==============================] - 620s 794ms/step - loss: 1.0659 - acc: 0.7187 - val_loss: 0.8118 - val_acc: 0.7730\n",
      "Epoch 14/130\n",
      "781/781 [==============================] - 616s 788ms/step - loss: 1.1476 - acc: 0.7144 - val_loss: 0.8612 - val_acc: 0.7571\n",
      "Epoch 15/130\n",
      "781/781 [==============================] - 615s 788ms/step - loss: 1.0204 - acc: 0.7291 - val_loss: 0.8139 - val_acc: 0.7776\n",
      "Epoch 16/130\n",
      "781/781 [==============================] - 610s 781ms/step - loss: 0.9899 - acc: 0.7372 - val_loss: 0.8011 - val_acc: 0.7752\n",
      "Epoch 17/130\n",
      "781/781 [==============================] - 634s 812ms/step - loss: 1.0291 - acc: 0.7399 - val_loss: 0.8776 - val_acc: 0.7733\n",
      "Epoch 18/130\n",
      "781/781 [==============================] - 632s 809ms/step - loss: 0.9758 - acc: 0.7436 - val_loss: 0.9437 - val_acc: 0.7518\n",
      "Epoch 19/130\n",
      "781/781 [==============================] - 628s 805ms/step - loss: 0.9790 - acc: 0.7467 - val_loss: 0.7774 - val_acc: 0.7908\n",
      "Epoch 20/130\n",
      "781/781 [==============================] - 635s 813ms/step - loss: 0.9751 - acc: 0.7490 - val_loss: 0.9345 - val_acc: 0.7632\n",
      "Epoch 21/130\n",
      "781/781 [==============================] - 618s 792ms/step - loss: 0.9633 - acc: 0.7525 - val_loss: 0.8566 - val_acc: 0.7826\n",
      "Epoch 22/130\n",
      "781/781 [==============================] - 619s 793ms/step - loss: 0.9474 - acc: 0.7558 - val_loss: 0.8488 - val_acc: 0.7808\n",
      "Epoch 23/130\n",
      "781/781 [==============================] - 624s 799ms/step - loss: 0.9429 - acc: 0.7559 - val_loss: 0.7694 - val_acc: 0.8034\n",
      "Epoch 24/130\n",
      "781/781 [==============================] - 622s 796ms/step - loss: 0.9370 - acc: 0.7600 - val_loss: 0.7046 - val_acc: 0.8177\n",
      "Epoch 25/130\n",
      "781/781 [==============================] - 623s 798ms/step - loss: 0.9305 - acc: 0.7619 - val_loss: 0.7945 - val_acc: 0.7929\n",
      "Epoch 26/130\n",
      "781/781 [==============================] - 626s 802ms/step - loss: 0.9380 - acc: 0.7612 - val_loss: 0.7632 - val_acc: 0.8031\n",
      "Epoch 27/130\n",
      "781/781 [==============================] - 623s 797ms/step - loss: 0.9300 - acc: 0.7666 - val_loss: 0.7918 - val_acc: 0.7947\n",
      "Epoch 28/130\n",
      "781/781 [==============================] - 621s 795ms/step - loss: 0.9188 - acc: 0.7657 - val_loss: 0.8678 - val_acc: 0.7772\n",
      "Epoch 29/130\n",
      "781/781 [==============================] - 622s 796ms/step - loss: 0.9122 - acc: 0.7648 - val_loss: 0.7884 - val_acc: 0.7975\n",
      "Epoch 30/130\n",
      "781/781 [==============================] - 621s 795ms/step - loss: 0.8857 - acc: 0.7711 - val_loss: 0.7910 - val_acc: 0.8007\n",
      "Epoch 31/130\n",
      "781/781 [==============================] - 621s 795ms/step - loss: 0.8914 - acc: 0.7719 - val_loss: 0.8289 - val_acc: 0.7956\n",
      "Epoch 32/130\n",
      "781/781 [==============================] - 624s 798ms/step - loss: 0.8942 - acc: 0.7719 - val_loss: 0.8670 - val_acc: 0.7809\n",
      "Epoch 33/130\n",
      "781/781 [==============================] - 621s 795ms/step - loss: 0.8813 - acc: 0.7737 - val_loss: 0.7429 - val_acc: 0.8117\n",
      "Epoch 34/130\n",
      "781/781 [==============================] - 624s 799ms/step - loss: 0.8585 - acc: 0.7767 - val_loss: 0.6987 - val_acc: 0.8142\n",
      "Epoch 35/130\n",
      "781/781 [==============================] - 625s 800ms/step - loss: 0.8579 - acc: 0.7791 - val_loss: 0.7419 - val_acc: 0.8076\n",
      "Epoch 36/130\n",
      "781/781 [==============================] - 623s 798ms/step - loss: 0.8612 - acc: 0.7773 - val_loss: 0.7902 - val_acc: 0.7960\n",
      "Epoch 37/130\n",
      "781/781 [==============================] - 626s 802ms/step - loss: 0.8395 - acc: 0.7813 - val_loss: 0.6885 - val_acc: 0.8221\n",
      "Epoch 38/130\n",
      "781/781 [==============================] - 637s 816ms/step - loss: 0.8346 - acc: 0.7824 - val_loss: 0.7633 - val_acc: 0.8053\n",
      "Epoch 39/130\n",
      "781/781 [==============================] - 625s 800ms/step - loss: 0.8145 - acc: 0.7822 - val_loss: 0.7628 - val_acc: 0.8106\n",
      "Epoch 40/130\n",
      "781/781 [==============================] - 627s 803ms/step - loss: 0.8108 - acc: 0.7841 - val_loss: 0.7533 - val_acc: 0.8058\n",
      "Epoch 41/130\n",
      "781/781 [==============================] - 623s 798ms/step - loss: 0.7987 - acc: 0.7863 - val_loss: 0.6626 - val_acc: 0.8369\n",
      "Epoch 42/130\n",
      "781/781 [==============================] - 624s 799ms/step - loss: 0.7903 - acc: 0.7866 - val_loss: 0.6248 - val_acc: 0.8437\n",
      "Epoch 43/130\n",
      "781/781 [==============================] - 625s 801ms/step - loss: 0.7663 - acc: 0.7922 - val_loss: 0.7035 - val_acc: 0.8152\n",
      "Epoch 44/130\n",
      "781/781 [==============================] - 627s 803ms/step - loss: 0.7537 - acc: 0.7904 - val_loss: 0.8192 - val_acc: 0.7929\n",
      "Epoch 45/130\n",
      "781/781 [==============================] - 625s 800ms/step - loss: 0.7428 - acc: 0.7959 - val_loss: 0.7351 - val_acc: 0.8055\n",
      "Epoch 46/130\n",
      "781/781 [==============================] - 627s 802ms/step - loss: 0.7370 - acc: 0.7964 - val_loss: 0.6566 - val_acc: 0.8266\n",
      "Epoch 47/130\n",
      "781/781 [==============================] - 629s 805ms/step - loss: 0.7301 - acc: 0.7952 - val_loss: 0.7749 - val_acc: 0.7969\n",
      "Epoch 48/130\n",
      "781/781 [==============================] - 624s 799ms/step - loss: 0.7212 - acc: 0.8005 - val_loss: 0.6903 - val_acc: 0.8228\n",
      "Epoch 49/130\n",
      "781/781 [==============================] - 627s 803ms/step - loss: 0.7145 - acc: 0.8018 - val_loss: 0.6683 - val_acc: 0.8289\n",
      "Epoch 50/130\n",
      "781/781 [==============================] - 627s 803ms/step - loss: 0.7140 - acc: 0.8024 - val_loss: 0.6436 - val_acc: 0.8306\n",
      "Epoch 51/130\n",
      "781/781 [==============================] - 630s 807ms/step - loss: 0.7071 - acc: 0.8026 - val_loss: 0.6840 - val_acc: 0.8209\n",
      "Epoch 52/130\n",
      "781/781 [==============================] - 660s 846ms/step - loss: 0.7056 - acc: 0.8026 - val_loss: 0.6565 - val_acc: 0.8302\n",
      "Epoch 53/130\n",
      "781/781 [==============================] - 648s 830ms/step - loss: 0.6993 - acc: 0.8050 - val_loss: 0.6399 - val_acc: 0.8351\n",
      "Epoch 54/130\n",
      "781/781 [==============================] - 648s 829ms/step - loss: 0.6974 - acc: 0.8064 - val_loss: 0.6589 - val_acc: 0.8282\n",
      "Epoch 55/130\n",
      "781/781 [==============================] - 640s 820ms/step - loss: 0.6968 - acc: 0.8072 - val_loss: 0.6348 - val_acc: 0.8346\n",
      "Epoch 56/130\n",
      "781/781 [==============================] - 636s 814ms/step - loss: 0.6888 - acc: 0.8081 - val_loss: 0.6925 - val_acc: 0.8212\n",
      "Epoch 57/130\n",
      "781/781 [==============================] - 638s 816ms/step - loss: 0.6882 - acc: 0.8099 - val_loss: 0.6669 - val_acc: 0.8272\n",
      "Epoch 58/130\n",
      "781/781 [==============================] - 636s 815ms/step - loss: 0.6872 - acc: 0.8090 - val_loss: 0.7284 - val_acc: 0.8098\n",
      "Epoch 59/130\n",
      "781/781 [==============================] - 636s 815ms/step - loss: 0.6832 - acc: 0.8113 - val_loss: 0.7314 - val_acc: 0.8096\n",
      "Epoch 60/130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - 638s 817ms/step - loss: 0.6799 - acc: 0.8098 - val_loss: 0.6837 - val_acc: 0.8271\n",
      "Epoch 61/130\n",
      "781/781 [==============================] - 637s 816ms/step - loss: 0.6835 - acc: 0.8115 - val_loss: 0.6951 - val_acc: 0.8182\n",
      "Epoch 62/130\n",
      "781/781 [==============================] - 635s 814ms/step - loss: 0.6781 - acc: 0.8119 - val_loss: 0.6249 - val_acc: 0.8412\n",
      "Epoch 63/130\n",
      "781/781 [==============================] - 635s 814ms/step - loss: 0.6793 - acc: 0.8116 - val_loss: 0.6867 - val_acc: 0.8192\n",
      "Epoch 64/130\n",
      "781/781 [==============================] - 644s 825ms/step - loss: 0.6772 - acc: 0.8147 - val_loss: 0.7150 - val_acc: 0.8130\n",
      "Epoch 65/130\n",
      "781/781 [==============================] - 640s 820ms/step - loss: 0.6677 - acc: 0.8144 - val_loss: 0.6081 - val_acc: 0.8458\n",
      "Epoch 66/130\n",
      "781/781 [==============================] - 640s 820ms/step - loss: 0.6759 - acc: 0.8129 - val_loss: 0.6173 - val_acc: 0.8435\n",
      "Epoch 67/130\n",
      "781/781 [==============================] - 638s 817ms/step - loss: 0.6664 - acc: 0.8162 - val_loss: 0.6400 - val_acc: 0.8384\n",
      "Epoch 68/130\n",
      "781/781 [==============================] - 640s 820ms/step - loss: 0.6665 - acc: 0.8159 - val_loss: 0.5773 - val_acc: 0.8521\n",
      "Epoch 69/130\n",
      "781/781 [==============================] - 644s 825ms/step - loss: 0.6688 - acc: 0.8172 - val_loss: 0.6158 - val_acc: 0.8442\n",
      "Epoch 70/130\n",
      "781/781 [==============================] - 642s 822ms/step - loss: 0.6689 - acc: 0.8140 - val_loss: 0.6029 - val_acc: 0.8457\n",
      "Epoch 71/130\n",
      "781/781 [==============================] - 643s 823ms/step - loss: 0.6656 - acc: 0.8171 - val_loss: 0.6164 - val_acc: 0.8411\n",
      "Epoch 72/130\n",
      "781/781 [==============================] - 644s 825ms/step - loss: 0.6664 - acc: 0.8171 - val_loss: 0.6476 - val_acc: 0.8319\n",
      "Epoch 73/130\n",
      "781/781 [==============================] - 644s 824ms/step - loss: 0.6634 - acc: 0.8174 - val_loss: 0.6136 - val_acc: 0.8450\n",
      "Epoch 74/130\n",
      "781/781 [==============================] - 645s 826ms/step - loss: 0.6604 - acc: 0.8171 - val_loss: 0.5911 - val_acc: 0.8487\n",
      "Epoch 75/130\n",
      "781/781 [==============================] - 646s 827ms/step - loss: 0.6574 - acc: 0.8209 - val_loss: 0.6579 - val_acc: 0.8317\n",
      "Epoch 76/130\n",
      "781/781 [==============================] - 649s 831ms/step - loss: 0.6625 - acc: 0.8206 - val_loss: 0.6394 - val_acc: 0.8386\n",
      "Epoch 77/130\n",
      "781/781 [==============================] - 646s 828ms/step - loss: 0.6164 - acc: 0.8333 - val_loss: 0.5683 - val_acc: 0.8590\n",
      "Epoch 78/130\n",
      "781/781 [==============================] - 647s 829ms/step - loss: 0.5992 - acc: 0.8369 - val_loss: 0.5641 - val_acc: 0.8570\n",
      "Epoch 79/130\n",
      "781/781 [==============================] - 648s 830ms/step - loss: 0.5973 - acc: 0.8374 - val_loss: 0.5823 - val_acc: 0.8535\n",
      "Epoch 80/130\n",
      "781/781 [==============================] - 648s 829ms/step - loss: 0.5867 - acc: 0.8408 - val_loss: 0.5740 - val_acc: 0.8550\n",
      "Epoch 81/130\n",
      "781/781 [==============================] - 658s 842ms/step - loss: 0.5810 - acc: 0.8421 - val_loss: 0.5610 - val_acc: 0.8543\n",
      "Epoch 82/130\n",
      "781/781 [==============================] - 664s 850ms/step - loss: 0.5905 - acc: 0.8380 - val_loss: 0.5739 - val_acc: 0.8541\n",
      "Epoch 83/130\n",
      "781/781 [==============================] - 656s 840ms/step - loss: 0.5828 - acc: 0.8409 - val_loss: 0.5612 - val_acc: 0.8591\n",
      "Epoch 84/130\n",
      "781/781 [==============================] - 650s 832ms/step - loss: 0.5797 - acc: 0.8408 - val_loss: 0.5151 - val_acc: 0.8679\n",
      "Epoch 85/130\n",
      "781/781 [==============================] - 655s 839ms/step - loss: 0.5740 - acc: 0.8423 - val_loss: 0.5281 - val_acc: 0.8652\n",
      "Epoch 86/130\n",
      "781/781 [==============================] - 652s 835ms/step - loss: 0.5711 - acc: 0.8446 - val_loss: 0.5173 - val_acc: 0.8644\n",
      "Epoch 87/130\n",
      "781/781 [==============================] - 656s 841ms/step - loss: 0.5668 - acc: 0.8435 - val_loss: 0.5895 - val_acc: 0.8487\n",
      "Epoch 88/130\n",
      "781/781 [==============================] - 656s 841ms/step - loss: 0.5648 - acc: 0.8425 - val_loss: 0.5358 - val_acc: 0.8650\n",
      "Epoch 89/130\n",
      "781/781 [==============================] - 653s 836ms/step - loss: 0.5658 - acc: 0.8462 - val_loss: 0.5278 - val_acc: 0.8651\n",
      "Epoch 90/130\n",
      "781/781 [==============================] - 656s 840ms/step - loss: 0.5600 - acc: 0.8454 - val_loss: 0.5002 - val_acc: 0.8714\n",
      "Epoch 91/130\n",
      "781/781 [==============================] - 656s 840ms/step - loss: 0.5616 - acc: 0.8437 - val_loss: 0.5403 - val_acc: 0.8603\n",
      "Epoch 92/130\n",
      "781/781 [==============================] - 660s 845ms/step - loss: 0.5546 - acc: 0.8458 - val_loss: 0.5208 - val_acc: 0.8665\n",
      "Epoch 93/130\n",
      "781/781 [==============================] - 658s 842ms/step - loss: 0.5636 - acc: 0.8427 - val_loss: 0.5027 - val_acc: 0.8702\n",
      "Epoch 94/130\n",
      "781/781 [==============================] - 666s 853ms/step - loss: 0.5549 - acc: 0.8437 - val_loss: 0.5585 - val_acc: 0.8566\n",
      "Epoch 95/130\n",
      "781/781 [==============================] - 664s 850ms/step - loss: 0.5565 - acc: 0.8456 - val_loss: 0.5010 - val_acc: 0.8700\n",
      "Epoch 96/130\n",
      "781/781 [==============================] - 662s 848ms/step - loss: 0.5509 - acc: 0.8463 - val_loss: 0.5552 - val_acc: 0.8577\n",
      "Epoch 97/130\n",
      "781/781 [==============================] - 670s 858ms/step - loss: 0.5517 - acc: 0.8461 - val_loss: 0.5314 - val_acc: 0.8636\n",
      "Epoch 98/130\n",
      "781/781 [==============================] - 663s 849ms/step - loss: 0.5467 - acc: 0.8469 - val_loss: 0.5281 - val_acc: 0.8624\n",
      "Epoch 99/130\n",
      "781/781 [==============================] - 663s 849ms/step - loss: 0.5469 - acc: 0.8472 - val_loss: 0.5077 - val_acc: 0.8684\n",
      "Epoch 100/130\n",
      "781/781 [==============================] - 670s 858ms/step - loss: 0.5490 - acc: 0.8474 - val_loss: 0.5419 - val_acc: 0.8599\n",
      "Epoch 101/130\n",
      "781/781 [==============================] - 668s 856ms/step - loss: 0.5491 - acc: 0.8459 - val_loss: 0.5966 - val_acc: 0.8494\n",
      "Epoch 102/130\n",
      "781/781 [==============================] - 664s 850ms/step - loss: 0.5446 - acc: 0.8478 - val_loss: 0.5286 - val_acc: 0.8682\n",
      "Epoch 103/130\n",
      "781/781 [==============================] - 670s 857ms/step - loss: 0.5453 - acc: 0.8475 - val_loss: 0.5824 - val_acc: 0.8522\n",
      "Epoch 104/130\n",
      "781/781 [==============================] - 669s 857ms/step - loss: 0.5462 - acc: 0.8486 - val_loss: 0.5613 - val_acc: 0.8512\n",
      "Epoch 105/130\n",
      "781/781 [==============================] - 670s 858ms/step - loss: 0.5457 - acc: 0.8466 - val_loss: 0.5525 - val_acc: 0.8589\n",
      "Epoch 106/130\n",
      "781/781 [==============================] - 673s 862ms/step - loss: 0.5396 - acc: 0.8470 - val_loss: 0.5043 - val_acc: 0.8708\n",
      "Epoch 107/130\n",
      "781/781 [==============================] - 668s 856ms/step - loss: 0.5422 - acc: 0.8474 - val_loss: 0.6469 - val_acc: 0.8368\n",
      "Epoch 108/130\n",
      "781/781 [==============================] - 671s 859ms/step - loss: 0.5342 - acc: 0.8515 - val_loss: 0.5411 - val_acc: 0.8635\n",
      "Epoch 109/130\n",
      "781/781 [==============================] - 672s 861ms/step - loss: 0.5415 - acc: 0.8480 - val_loss: 0.5371 - val_acc: 0.8638\n",
      "Epoch 110/130\n",
      "781/781 [==============================] - 671s 860ms/step - loss: 0.5403 - acc: 0.8483 - val_loss: 0.5403 - val_acc: 0.8588\n",
      "Epoch 111/130\n",
      "781/781 [==============================] - 671s 860ms/step - loss: 0.5412 - acc: 0.8480 - val_loss: 0.4843 - val_acc: 0.8720\n",
      "Epoch 112/130\n",
      "781/781 [==============================] - 671s 859ms/step - loss: 0.5354 - acc: 0.8493 - val_loss: 0.5209 - val_acc: 0.8625\n",
      "Epoch 113/130\n",
      "781/781 [==============================] - 672s 861ms/step - loss: 0.5343 - acc: 0.8489 - val_loss: 0.5497 - val_acc: 0.8566\n",
      "Epoch 114/130\n",
      "781/781 [==============================] - 672s 860ms/step - loss: 0.5380 - acc: 0.8469 - val_loss: 0.5023 - val_acc: 0.8726\n",
      "Epoch 115/130\n",
      "781/781 [==============================] - 675s 864ms/step - loss: 0.5339 - acc: 0.8494 - val_loss: 0.6016 - val_acc: 0.8437\n",
      "Epoch 116/130\n",
      "781/781 [==============================] - 674s 862ms/step - loss: 0.5333 - acc: 0.8490 - val_loss: 0.5162 - val_acc: 0.8636\n",
      "Epoch 117/130\n",
      "781/781 [==============================] - 674s 863ms/step - loss: 0.5311 - acc: 0.8493 - val_loss: 0.5265 - val_acc: 0.8628\n",
      "Epoch 118/130\n",
      "781/781 [==============================] - 679s 870ms/step - loss: 0.5353 - acc: 0.8491 - val_loss: 0.5521 - val_acc: 0.8562\n",
      "Epoch 119/130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781/781 [==============================] - 682s 874ms/step - loss: 0.5349 - acc: 0.8490 - val_loss: 0.5264 - val_acc: 0.8647\n",
      "Epoch 120/130\n",
      "781/781 [==============================] - 706s 904ms/step - loss: 0.5334 - acc: 0.8508 - val_loss: 0.5195 - val_acc: 0.8634\n",
      "Epoch 121/130\n",
      "781/781 [==============================] - 710s 908ms/step - loss: 0.5317 - acc: 0.8484 - val_loss: 0.4983 - val_acc: 0.8731\n",
      "Epoch 122/130\n",
      "781/781 [==============================] - 678s 869ms/step - loss: 0.5337 - acc: 0.8506 - val_loss: 0.5344 - val_acc: 0.8622\n",
      "Epoch 123/130\n",
      "781/781 [==============================] - 680s 871ms/step - loss: 0.5269 - acc: 0.8528 - val_loss: 0.5081 - val_acc: 0.8716\n",
      "Epoch 124/130\n",
      "781/781 [==============================] - 684s 876ms/step - loss: 0.5312 - acc: 0.8498 - val_loss: 0.5224 - val_acc: 0.8629\n",
      "Epoch 125/130\n",
      "781/781 [==============================] - 681s 872ms/step - loss: 0.5325 - acc: 0.8487 - val_loss: 0.5062 - val_acc: 0.8714\n",
      "Epoch 126/130\n",
      "781/781 [==============================] - 685s 877ms/step - loss: 0.5286 - acc: 0.8501 - val_loss: 0.5165 - val_acc: 0.8672\n",
      "Epoch 127/130\n",
      "781/781 [==============================] - 683s 875ms/step - loss: 0.5309 - acc: 0.8480 - val_loss: 0.4987 - val_acc: 0.8704\n",
      "Epoch 128/130\n",
      "781/781 [==============================] - 690s 884ms/step - loss: 0.5274 - acc: 0.8517 - val_loss: 0.5325 - val_acc: 0.8656\n",
      "Epoch 129/130\n",
      "781/781 [==============================] - 687s 880ms/step - loss: 0.5218 - acc: 0.8544 - val_loss: 0.5059 - val_acc: 0.8708\n",
      "Epoch 130/130\n",
      "781/781 [==============================] - 684s 875ms/step - loss: 0.5229 - acc: 0.8517 - val_loss: 0.5482 - val_acc: 0.8589\n"
     ]
    }
   ],
   "source": [
    "# 拡張データを使って学習を行う\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 学習率をスケジューリングする\n",
    "def lr_schedule(epoch):\n",
    "    lrate = 0.001      # 1～75回の学習率\n",
    "    if epoch > 75:\n",
    "        lrate = 0.0005 # 76～100回の学習率\n",
    "    elif epoch > 100:\n",
    "        lrate = 0.0003 # 101回以降の学習率\n",
    "    return lrate\n",
    " \n",
    "# データ拡張\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,      # 15度の範囲でランダムに回転させる\n",
    "    width_shift_range=0.1,  # 横サイズの0.1の割合でランダムに水平移動\n",
    "    height_shift_range=0.1, # 縦サイズの0.1の割合でランダムに垂直移動\n",
    "    horizontal_flip=True,   # 水平方向にランダムに反転、左右の入れ替え\n",
    "    zoom_range=0.2,         # ランダムに拡大\n",
    "    )\n",
    " \n",
    "# ミニバッチのサイズ\n",
    "batch_size = 64\n",
    "# 学習回数\n",
    "epochs = 130\n",
    "\n",
    "# 学習を行う\n",
    "history = model.fit_generator(\n",
    "    # 拡張データをミニバッチの数だけ生成\n",
    "    datagen.flow(x_train,\n",
    "                 y_train,\n",
    "                 batch_size=batch_size),\n",
    "    # 1回の学習におけるステップ数\n",
    "    # 画像の枚数をミニバッチのサイズで割った整数値\n",
    "    steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "    epochs=epochs, # 学習回数\n",
    "    verbose=1,     # 学習の進捗状況を出力する\n",
    "    # テストデータ\n",
    "    validation_data=(x_test,y_test),\n",
    "    # 学習率のスケジューラーとしてlr_schedule()を呼ぶ\n",
    "    callbacks=[LearningRateScheduler(lr_schedule)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習回数ごとの精度と損失の変化をグラフにする\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_history(history):\n",
    "    # 精度の履歴をプロット\n",
    "    plt.plot(history.history['acc'],\"-\",label=\"accuracy\")\n",
    "    plt.plot(history.history['val_acc'],\"-\",label=\"val_acc\")\n",
    "    plt.title('model accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    # 損失の履歴をプロット\n",
    "    plt.plot(history.history['loss'],\"-\",label=\"loss\",)\n",
    "    plt.plot(history.history['val_loss'],\"-\",label=\"val_loss\")\n",
    "    plt.title('model loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "# modelに学習させた時の変化の様子をplot\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
